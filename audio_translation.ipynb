{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GGYyW9HCqQ__",
        "bwv1vHt5t4Z6",
        "eJh6-iw08tN1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIExnD3xclfb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b8c66c-f093-4e44-9982-9d529a5000b6"
      },
      "source": [
        "# Install Libraries\n",
        "!sudo apt-get install portaudio19-dev\n",
        "!pip install playsound\n",
        "!pip install SpeechRecognition\n",
        "!pip install googletrans\n",
        "!pip install gTTs\n",
        "!pip install gTTS-token\n",
        "!pip install pygobject\n",
        "!pip install PyAudio\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: playsound in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.2)\n",
            "Requirement already satisfied: gTTs in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTs) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTs) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTs) (2025.4.26)\n",
            "Requirement already satisfied: gTTS-token in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gTTS-token) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gTTS-token) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gTTS-token) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gTTS-token) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gTTS-token) (2025.4.26)\n",
            "Requirement already satisfied: pygobject in /usr/local/lib/python3.11/dist-packages (3.42.0)\n",
            "Requirement already satisfied: pycairo>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygobject) (1.28.0)\n",
            "Requirement already satisfied: PyAudio in /usr/local/lib/python3.11/dist-packages (0.2.14)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary modules required\n",
        "from playsound import playsound\n",
        "import speech_recognition as sr\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import asyncio\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "5qJXEZfKpEE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic=('afrikaans', 'af', 'albanian', 'sq', 'amharic', 'am',\n",
        "\t'arabic', 'ar', 'armenian', 'hy', 'azerbaijani', 'az',\n",
        "'basque', 'eu', 'belarusian', 'be', 'bengali', 'bn', 'bosnian',\n",
        "\t'bs', 'bulgarian', 'bg', 'catalan', 'ca',\n",
        "'cebuano', 'ceb', 'chichewa', 'ny', 'chinese (simplified)',\n",
        "\t'zh-cn', 'chinese (traditional)', 'zh-tw',\n",
        "'corsican', 'co', 'croatian', 'hr', 'czech', 'cs', 'danish',\n",
        "\t'da', 'dutch', 'nl', 'english', 'en', 'esperanto',\n",
        "'eo', 'estonian', 'et', 'filipino', 'tl', 'finnish', 'fi',\n",
        "\t'french', 'fr', 'frisian', 'fy', 'galician', 'gl',\n",
        "'georgian', 'ka', 'german', 'de', 'greek', 'el', 'gujarati',\n",
        "\t'gu', 'haitian creole', 'ht', 'hausa', 'ha',\n",
        "'hawaiian', 'haw', 'hebrew', 'he', 'hindi', 'hi', 'hmong',\n",
        "\t'hmn', 'hungarian', 'hu', 'icelandic', 'is', 'igbo',\n",
        "'ig', 'indonesian', 'id', 'irish', 'ga', 'italian', 'it',\n",
        "\t'japanese', 'ja', 'javanese', 'jw', 'kannada', 'kn',\n",
        "'kazakh', 'kk', 'khmer', 'km', 'korean', 'ko', 'kurdish (kurmanji)',\n",
        "\t'ku', 'kyrgyz', 'ky', 'lao', 'lo',\n",
        "'latin', 'la', 'latvian', 'lv', 'lithuanian', 'lt', 'luxembourgish',\n",
        "\t'lb', 'macedonian', 'mk', 'malagasy',\n",
        "'mg', 'malay', 'ms', 'malayalam', 'ml', 'maltese', 'mt', 'maori',\n",
        "\t'mi', 'marathi', 'mr', 'mongolian', 'mn',\n",
        "'myanmar (burmese)', 'my', 'nepali', 'ne', 'norwegian', 'no',\n",
        "\t'odia', 'or', 'pashto', 'ps', 'persian',\n",
        "'fa', 'polish', 'pl', 'portuguese', 'pt', 'punjabi', 'pa',\n",
        "\t'romanian', 'ro', 'russian', 'ru', 'samoan',\n",
        "'sm', 'scots gaelic', 'gd', 'serbian', 'sr', 'sesotho',\n",
        "\t'st', 'shona', 'sn', 'sindhi', 'sd', 'sinhala',\n",
        "'si', 'slovak', 'sk', 'slovenian', 'sl', 'somali', 'so',\n",
        "\t'spanish', 'es', 'sundanese', 'su',\n",
        "'swahili', 'sw', 'swedish', 'sv', 'tajik', 'tg', 'tamil',\n",
        "\t'ta', 'telugu', 'te', 'thai', 'th', 'turkish', 'tr',\n",
        "'ukrainian', 'uk', 'urdu', 'ur', 'uyghur', 'ug', 'uzbek',\n",
        "\t'uz', 'vietnamese', 'vi', 'welsh', 'cy', 'xhosa', 'xh',\n",
        "'yiddish', 'yi', 'yoruba', 'yo', 'zulu', 'zu')\n"
      ],
      "metadata": {
        "id": "3J8tDw8LpKSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 1 - Real time translation using microphone input**\n",
        "\n"
      ],
      "metadata": {
        "id": "GGYyW9HCqQ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enable microphone\n",
        "import pyaudio\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "info = p.get_host_api_info_by_index(0)\n",
        "numdevices = info.get('deviceCount')\n",
        "for i in range(0, numdevices):\n",
        "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
        "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
        "\n",
        "p.terminate()"
      ],
      "metadata": {
        "id": "NPzxe7lTN_9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture Voice\n",
        "# takes command through microphone\n",
        "def takecommand():\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"listening.....\")\n",
        "        r.pause_threshold = 1\n",
        "        audio = r.listen(source)\n",
        "\n",
        "    try:\n",
        "        print(\"Recognizing.....\")\n",
        "        query = r.recognize_google(audio, language='en-in')\n",
        "        print(f\"user said {query}\\n\")\n",
        "    except Exception as e:\n",
        "        print(\"say that again please.....\")\n",
        "        return \"None\"\n",
        "    return query"
      ],
      "metadata": {
        "id": "IO3xudVlqcen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking voice input from the user\n",
        "query = takecommand()\n",
        "while (query == \"None\"):\n",
        "\tquery = takecommand()\n"
      ],
      "metadata": {
        "id": "nzNmYnP5qoAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def destination_language():\n",
        "\tprint(\"Enter the language in which you want to convert : Ex. Hindi , English , etc.\")\n",
        "\tprint()\n",
        "\n",
        "\t# Input destination language in which the user\n",
        "\t# wants to translate\n",
        "\tto_lang = takecommand()\n",
        "\twhile (to_lang == \"None\"):\n",
        "\t\tto_lang = takecommand()\n",
        "\tto_lang = to_lang.lower()\n",
        "\treturn to_lang\n",
        "\n",
        "to_lang = destination_language()\n",
        "\n",
        "# Mapping it with the code\n",
        "while (to_lang not in dic):\n",
        "\tprint(\"Language in which you are trying to convert is currently not available ,please input some other language\")\n",
        "\tprint()\n",
        "\tto_lang = destination_language()\n",
        "\n",
        "to_lang = dic[dic.index(to_lang)+1]\n"
      ],
      "metadata": {
        "id": "o5Zst2JJshxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invoking Translator\n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "QEzenj70tJfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating from src to dest\n",
        "text_to_translate = translator.translate(query, dest=to_lang)\n",
        "text = text_to_translate.text"
      ],
      "metadata": {
        "id": "MfDkNhV0tLKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating from src to dest\n",
        "text_to_translate = translator.translate(query, dest=to_lang)\n",
        "text = text_to_translate.text"
      ],
      "metadata": {
        "id": "5MFg3DrBtPbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Google-Text-to-Speech ie, gTTS() method\n",
        "# to speak the translated text into the\n",
        "# destination language which is stored in to_lang.\n",
        "# Also, we have given 3rd argument as False because\n",
        "# by default it speaks very slowly\n",
        "speak = gTTS(text=text, lang=to_lang, slow=False)\n",
        "\n",
        "# Using save() method to save the translated\n",
        "# speech in capture_voice.mp3\n",
        "speak.save(\"captured_voice.mp3\")\n",
        "\n",
        "# Using OS module to run the translated voice.\n",
        "playsound('captured_voice.mp3')\n",
        "os.remove('captured_voice.mp3')\n",
        "print(text)"
      ],
      "metadata": {
        "id": "LfP2mxIOtjT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 2 - Audio to Text translation**\n",
        "\n"
      ],
      "metadata": {
        "id": "bwv1vHt5t4Z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import input file\n",
        "audio = AudioSegment.from_mp3(\"input.mp3\") # or other format\n",
        "# audio.export(\"input.wav\", format=\"wav\") #Only if input is not in .wav format"
      ],
      "metadata": {
        "id": "9oxMC1yb25IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()  # Ensure nest_asyncio is applied\n",
        "\n",
        "async def translate_text(text, source_lang='en', target_lang='bn'):  # Changed function name\n",
        "    translator = Translator()\n",
        "    translation = await translator.translate(text, src=source_lang, dest=target_lang)\n",
        "    return translation.text\n",
        "\n",
        "async def main():\n",
        "    r = sr.Recognizer()\n",
        "    with sr.AudioFile(\"/content/Speaker26_000.wav\") as source:\n",
        "        audio_data = r.record(source)\n",
        "    try:\n",
        "        text = r.recognize_google(audio_data)\n",
        "        print(\"Original Text: \" + text)\n",
        "        translated_text = await translate_text(text)  # Await the translation\n",
        "        print(\"Translated Text: \" + translated_text)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Speech Recognition could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Could not request results from Speech Recognition service; {0}\".format(e))\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "q_fOB5uewU1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hGb3ifU-8gQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y-SgNeRu8pPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 3 - Audio to Audio translation**"
      ],
      "metadata": {
        "id": "eJh6-iw08tN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio"
      ],
      "metadata": {
        "id": "eHUDNIRk8518"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "async def audio_to_audio_translation(input_audio_path, output_audio_path, source_lang='en', target_lang='es'):\n",
        "    \"\"\"Translates an audio file to another language asynchronously.\"\"\"\n",
        "\n",
        "    # 1. Speech-to-Text\n",
        "    r = sr.Recognizer()\n",
        "    with sr.AudioFile(input_audio_path) as source:\n",
        "        audio_data = r.record(source)\n",
        "    try:\n",
        "        text = r.recognize_google(audio_data, language=source_lang)\n",
        "        print(f\"Recognized text: {text}\")\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio\")\n",
        "        return\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Speech Recognition service; {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Text Translation (Asynchronous)\n",
        "    translator = Translator()\n",
        "    translation = await translator.translate(text, src=source_lang, dest=target_lang)  # Await translation\n",
        "    translated_text = translation.text\n",
        "    print(f\"Translated text: {translated_text}\")\n",
        "\n",
        "    # 3. Text-to-Speech\n",
        "    tts = gTTS(text=translated_text, lang=target_lang)\n",
        "    tts.save(output_audio_path)\n",
        "    print(f\"Saved translated audio to: {output_audio_path}\")\n"
      ],
      "metadata": {
        "id": "4ikNAelD-uOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "async def main():\n",
        "    input_audio_path = \"/content/Speaker26_000.wav\"  # Replace with your input audio file path\n",
        "    output_audio_path = \"/content/Speaker26_000_bengali.wav\"  # Replace with desired output audio file path\n",
        "    source_language = \"en\"  # Replace with the source language code\n",
        "    target_language = \"bn\"  # Replace with the target language code\n",
        "\n",
        "    await audio_to_audio_translation(input_audio_path, output_audio_path, source_language, target_language)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "FnMOaT82-NV1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "c6e3fb4e-7971-4ff5-9ff1-f1c46aafd1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Speaker26_000.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b649ae502ac7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-b649ae502ac7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bn\"\u001b[0m  \u001b[0;31m# Replace with the target language code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0maudio_to_audio_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_audio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_audio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-91a694bbf8fa>\u001b[0m in \u001b[0;36maudio_to_audio_translation\u001b[0;34m(input_audio_path, output_audio_path, source_lang, target_lang)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 1. Speech-to-Text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_audio_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0maudio_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# attempt to read the file as WAV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Speaker26_000.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 4 - Audio Translation through MarinaMT"
      ],
      "metadata": {
        "id": "O_IVfhq2PVPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer"
      ],
      "metadata": {
        "id": "HpHyJrVFPeyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained models and tokenizers for different languages\n",
        "models = {\n",
        "    'es': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-es'),\n",
        "    'fr': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-fr'),\n",
        "    'it': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-it'),\n",
        "    'pt': MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
        "}\n",
        "\n",
        "tokenizers = {\n",
        "    'es': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es'),\n",
        "    'fr': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-fr'),\n",
        "    'it': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-it'),\n",
        "    'pt': MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yDiBI8xWRG_y",
        "outputId": "9cc70deb-634c-4c84-c478-717f714b56bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio to text conversion\n",
        "def audio2text(audio_path):\n",
        "    r = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio_data = r.record(source)\n",
        "    try:\n",
        "        audio_text = r.recognize_google(audio_data)\n",
        "        print(\"Original Text: \" + audio_text)\n",
        "\n",
        "        return audio_text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Speech Recognition could not understand audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(\"Could not request results from Speech Recognition service; {0}\".format(e))"
      ],
      "metadata": {
        "id": "KHSva9hNBhgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "audio_file = AudioSegment.from_file(\"/content/what_is_knowledge.mp3\", format=\"mp3\")  # Replace with your file\n",
        "audio_file = audio_file.set_frame_rate(16000)\n",
        "audio_file = audio_file.set_channels(1)\n",
        "audio_file = audio_file.set_sample_width(2)\n",
        "audio_file.export(\"converted_audio.wav\", format=\"wav\")  # Save as WAV\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELb67P2lB8Pw",
        "outputId": "86e8a4c5-8baf-43c4-e04b-40477763b17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='converted_audio.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted_text = audio2text(\"/content/converted_audio.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7x1U9YBcH2N",
        "outputId": "84915b03-fc2f-4cbf-e230-7048ccac7bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: in this lecture Professor Colin mcginn deciphers what we mean when we say we know something to be true he traces the history of philosophical skepticism giving the listener several historical Arguments for the theory of knowledge and also touching on arguments made by the likes of Plato Descartes and other important philosophers this lecture is a foundational exercise for the rest of the program with mcginn arguing that for someone to begin thinking philosophically he or she must first understand the methods of thinking that go into the pursuit of true knowledge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text translation\n",
        "def translate_text(input_text, target_language):\n",
        "    tokenizer = tokenizers[target_language]\n",
        "    model = models[target_language]\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    output = model.generate(input_ids=input_ids, max_length=50)\n",
        "    translated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "jS01jLbVgVCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual translation\n",
        "translated_text = translate_text(converted_text, 'it')\n",
        "print(\"Translated Text: \" + translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKeKh1Dggl9G",
        "outputId": "7bca45f2-d993-4a26-a5b7-096f5b84dc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Text: In questa lezione il professor Colin Mcginn decifra ci√≤ che intendiamo quando diciamo che sappiamo qualcosa di vero ripercorre la storia dello scetticismo filosofico dando all'ascoltatore diversi argomenti storici per la teoria della conoscenza e tocca\n"
          ]
        }
      ]
    }
  ]
}